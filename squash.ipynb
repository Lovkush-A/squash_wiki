{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape data\n",
    "\n",
    "This notebook scrapes data from the Year End World Top 10 sections of the [Men's](https://en.wikipedia.org/wiki/Official_Men%27s_Squash_World_Ranking) and [Women's](https://en.wikipedia.org/wiki/Official_Women%27s_Squash_World_Ranking) Squash World Ranking wikipedia pages and stores the data in `csv` files. The only way to fully understand how the functions in this notebook work is to visit the pages yourself and inspect the HTML.\n",
    "\n",
    "Some things to notice:\n",
    "\n",
    "* the first column of the tables are just the ranks 1 to 10. hence we ignore them. this is done by using `[1:]` when looping through columns in `table_to_pandas`\n",
    "* in some tables they include the ranking points as well as the player names. we ignore ranking points. this is done by creating function `is_not_numeric`\n",
    "* the top row of each table is the years and the other rows contains player information. hence in `table_to_pandas` we have two separate list comprehensions, one for the years and one for the player names\n",
    "* the first table of the section in the mens page has lots of blank entries and does not fit the pattern of the other tables. i have chosen to just ignore the first table. see `url_to_pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ['https://en.wikipedia.org/wiki/Official_Women%27s_Squash_World_Ranking',\n",
    "    'https://en.wikipedia.org/wiki/Official_Men%27s_Squash_World_Ranking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _is_not_numeric(s):\n",
    "    \"\"\"\n",
    "    check if the string s is numeric\n",
    "    \n",
    "    Args:\n",
    "        s, string\n",
    "    Returns:\n",
    "        boolean\n",
    "    \"\"\"\n",
    "    try:\n",
    "        float(s)\n",
    "    except ValueError:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def _table_to_pandas(table):\n",
    "    \"\"\"\n",
    "    extract information from a single table from the Year End World Top 10\n",
    "    section of the squash world ranking wiki pages, and store it in a pandas\n",
    "    frame\n",
    "    \n",
    "    Args:\n",
    "        table\n",
    "            a string of an html table from the squash wiki page\n",
    "    \n",
    "    Returns:\n",
    "        pd.dataframe\n",
    "            index is from 1 to 10\n",
    "            column names are the years\n",
    "            entries are player names\n",
    "    \"\"\"\n",
    "    rows = table.find_all(\"tr\")\n",
    "    \n",
    "    # the top row (hence rows[0]) of each table contains the years\n",
    "    # first column of each table contains ranks, hence why we have [1:]\n",
    "    years = [col.text.replace(\"\\n\", \"\") for col in rows[0].find_all(\"th\")[1:]]\n",
    "\n",
    "    # the other rows (hence rows[1:]) of each table contains the players' names\n",
    "    players = [\n",
    "        [\n",
    "            col.text.replace(\"\\n\", \"\")\n",
    "            for col in row.find_all(\"td\")[1:]\n",
    "            if _is_not_numeric(col.text.replace(\"\\n\", \"\"))\n",
    "        ]\n",
    "        for row in rows[1:]\n",
    "    ]\n",
    "\n",
    "    return pd.DataFrame(players, columns=years, index=range(1, 11))\n",
    "\n",
    "\n",
    "def url_to_pandas(url, ignore_first_table = False):\n",
    "    \"\"\"\n",
    "    extract information from all tables from the Year End World Top 10\n",
    "    section of the squash world ranking wiki pages, and store it in a pandas\n",
    "    frame\n",
    "    \n",
    "    Args:\n",
    "        url\n",
    "            a string containing url to the wiki page\n",
    "    \n",
    "    Returns:\n",
    "        df_stack\n",
    "            a pd.DataFrame with three columns: rank, year and player\n",
    "    \"\"\"\n",
    "    html = requests.get(url).text\n",
    "    \n",
    "    # start and end determined by manually inspecting html of the wiki pages\n",
    "    start = html.find('id=\"Year_end_world_top_10_players')\n",
    "    end = html.find('id=\"Year-end_number_1')\n",
    "    \n",
    "    tables = BeautifulSoup(html[start:end], \"html.parser\").find_all(\"table\")\n",
    "    \n",
    "    # in mens page, first table in the wiki page does not fit the pattern\n",
    "    if ignore_first_table:\n",
    "        tables = tables[1:]\n",
    "    \n",
    "    df = pd.concat([_table_to_pandas(t) for t in tables], axis=1)\n",
    "    \n",
    "    # in general, df.stack() creates new frame whose multiindex consists of the\n",
    "    # the index and columns of df\n",
    "    # in this instance, df.stack's multiindexx is [rank, year] and its single\n",
    "    # column contains names of players\n",
    "    df_stack = df.stack().reset_index()\n",
    "    df_stack.columns = [\"rank\", \"year\", \"player\"]\n",
    "\n",
    "    return df_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = url_to_pandas(urls[1], ignore_first_table=True)\n",
    "df_f = url_to_pandas(urls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m.to_csv('male_raw.csv')\n",
    "df_f.to_csv('female_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def player_summaries(df):\n",
    "    players = df.groupby(\"player\").agg(\n",
    "        {\"rank\": [np.mean, \"count\", np.min, np.max], \"year\": [np.min, np.max]}\n",
    "    )\n",
    "\n",
    "    players.columns = [\n",
    "        \"average_rank\",\n",
    "        \"years_in_top10\",\n",
    "        \"best_rank\",\n",
    "        \"worst_rank\",\n",
    "        \"earliest_year\",\n",
    "        \"latest_year\",\n",
    "    ]\n",
    "    players.sort_values(by=[\"average_rank\"], inplace=True)\n",
    "\n",
    "    return players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_f = player_summaries(pd.read_csv('female_raw.csv', index_col=0))\n",
    "players_m = player_summaries(pd.read_csv('male_raw.csv', index_col=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_m.to_csv('male.csv')\n",
    "players_f.to_csv('female.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visuals and clustering and dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_m = pd.read_csv('male.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
